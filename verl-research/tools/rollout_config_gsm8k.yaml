hydra:
  searchpath:
    - file://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

# Data
data:
  max_prompt_length: 1024
  max_response_length: 1024
  train_batch_size: 32
  return_raw_chat: true

# Model
actor_rollout_ref:
  hybrid_engine: true
  model:
    path: "Qwen/Qwen3-4B"
  rollout:
    name: sglang  # or vllm if desired
    mode: async
    calculate_log_probs: true
    tensor_model_parallel_size: 1
    data_parallel_size: 1
    pipeline_model_parallel_size: 1
    expert_parallel_size: 1
    multi_turn:
      enable: true
      max_assistant_turns: 8
      max_user_turns: 1
      tool_config_path: "examples/sglang_multiturn/config/tool_config/gsm8k_tool_config.yaml"
      interaction_config_path: "verl-research/tools/interaction_config_codecheck.yaml"  # replace with your game interaction

# Trainer (kept for compatibility; rollout_only does not run optimizer)
trainer:
  nnodes: 1
  n_gpus_per_node: 1
  total_epochs: 1
  val_before_train: false
  val_only: false
  save_freq: -1

# Algorithm placeholders (left default)
algorithm:
  adv_estimator: gae
  gamma: 1.0
  lam: 1.0
